tweet=read.csv("tweets.csv",stringsAsFactors = FALSE)
str(tweet)
tweetsNegative=as.factor(tweet$Avg<=-1)
table(tweetsNegative)
corpus=Corpus(VectorSource(tweet$Tweet))
corpus=Corpus(corpus,content_transformer(tolower))
corpus=tm_map(corpus,PlainTextDocument)
corpus[[1]]$content
corpus=tm_map(corpus,removePunctuation)
stopwords("english")[1:10]
corpus=tm_map(corpus,removeWords,c("apple",stopwords("english")))
corpus=tm_map(corpus,stemDocument)
frequencies=DocumentTermMatrix(corpus)
frequencies
inspect(frequencies[1000:1005,500:505])
findFreqTerms(frequencies,lowfreq = 20)
sparse=removeSparseTerms(frequencies,0.995)
sparse
tweetsparse=as.data.frame(as.matrix(sparse))
colnames(tweetsparse)=make.names(colnames(tweetsparse))
tweetsparse$Negative=tweetsNegative
library(caTools)
set.seed(123)
spl=sample.split(tweetsparse$Negative,0.7)
trainSparse=subset(tweetsparse,spl==TRUE)
testSparse=subset(tweetsparse,spl==FALSE)
findFreqTerms(frequencies,lowfreq = 100)
library(rpart.plot)
cart=rpart(Negative~.,data=trainSparse,method="class")
prp(cart)
predic=predict(cart,newdata=testSparse,type="class")
table(testSparse$Negative,predic)
library(randomForest)
rf=randomForest(Negative~.,data=trainSparse)
predictrf=predict(rf,testSparse)
table(testSparse$Negative,predictrf)
lrg=glm(Negative~.,data=trainSparse,family=binomial)
predglm=predict(lrg,newdata=testSparse,type="response")
table(testSparse$Negative,predglm>0.5)
